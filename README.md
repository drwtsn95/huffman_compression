# Запуск
На системе должен быть установлен  
`python 3.10`

Установим необходимую библиотеку  
`pip install -r requirements.txt`

Чтобы сжать файл, используйте команду  
`python3 huffman_compression.py filename`

Чтобы расжать файл, используйте команду  
`python3 huffman_compression.py --decompress filename`

# Пояснительная записка

## Используемые конструкции
Ради интереса, часть программы я реализовал в функциональном стиле, используя `pattern-matching`, появившийся в `python 3.10`  
Использование декоратора `@dataclass` необходимо для красоты и наглядности, чтобы не прописывать очевидный код конструкторов.
Также я использовал библиотеку `bitarray` для эффективной и удобной работы с битовыми последовательностями, написанную на языке C.

## Решение проблемы паддинга в сжатом файле
В результате работы алгоритма может получиться так, что итоговый размер сжатых данных в битах не будет кратен 8-ми.
В таком случае в конце последнего байта сжатых данных будут содержаться данные, которые могут быть по ошибке восприняты, как кодовое слово.  
Я решил эту проблему, добавив "257-й байт", абстракцию, выполняющую роль `EOF`, которая в реальности имеет только образ - кодовое слово, но 
не имеет прообраза.

## Решение проблемы хранения кодовой таблицы
Кодовая таблица создается из дерева кода, построенного в рамках работы алгоритма. Поэтому мы можем сериализовать не её, а дерево, 
а потом быстро восстановить таблицу по дереву. С помощью рекурсивной функции производится прямой обход дерева и
его сериализация получается следующим образом:
- Если текущая вершина является внутренней - добавляем в результат бит '0'.
- Если текущая вершина является листом - добавляем в результат бит '1', а за ним записываем:
    1. Если лист соответствует `EOF`, бит '1'.
    2. Иначе, бит '0', а за ним байт, содержащийся в данных листа.

Сериализованная таким образом кодовая таблица помещается в сжатом файле непосредственно перед данными (без паддинга последнего байта).
Десериализация также проводится рекурсивно, благодаря чему алгоритм десериализации останавливается "где надо", 
и мы можем быть уверены, что оставшийся поток битов уже представляет данные, которые нам требуется декодировать с помощью таблицы. 
Т.е. не требуется каких-либо разделителей, помогающих отличить кодовую таблицу от самих данных внутри сжатого файла.

## Декодирование
Поскольку мне приходится работать в общем случае с битовой последовательностью, перед "тяжелыми" процедурами я переворачиваю эту последовательность,
чтобы вместо `pop(0)` использовать `pop()`, а также удалять обработанные биты из последовательности с конца, а не начала. Потому что так быстрее.
Значительно.  
В первой версии программы я проводил декодирование не с помощью кодовой таблицы, а с помощью дерева. По сути получалось что-то вроде автомата, 
под капотом которого был проход дерева от корня, до одного из листьев. И так для каждого кодового слова. Этот способ оказался очень медленным 
из-за того, что:
1. Я читал поток всегда побитово, по одному вызову `pop()` на один бит сжатых данных.
2. Pattern matching - это конечно красиво, но когда он происходит слишком часто (на каждый бит данных, размер которых может быть крайне большим, 
в отличие от сериализованной кодовой таблицы). Тем более, неизвестно, насколько быстро он работает, особенно в отношении классов, прототипы которых
не могут похвастаться эргономичностью.

Поэтому, декодирую данные по таблице, полученной инвертированием таблицы, с помощью которой кодирование и проводилось.  
Вначале я сделал так:
- Считываю `N` бит, где `N` - длина кратчайшего из кодовых слов, а дальше дочитываю по одному биту по необходимости, до нахождения соответствия.

Но затем я принял решение поменять стратегию и в финальной версии программы сделал так:
- Вычисляю длину `N` самого длинного кодового слова из таблицы. 
- Строю новую таблицу, в которой `2^N` записей, ключи уникальны (битовые векторы длины `N`), а значения выставляются так:
если некоторое кодовое слово является префиксом ключа, то в качестве значения берем пару  
`(<байт, соответствующий кодовому слову>; <длина кодового слова>)`  
Эта идея легитимна благодаря тому факту, что код является префиксным.
- Смотрю первые `N` бит и сразу же нахожу в таблице нужный байт, а также длину кодового слова `l`. Именно `l` бит я затем и "пролистываю".

## Наблюдения
- Всё-таки `python` - не тот язык, на котором пишется что-то быстрое. Поэтому хорошо позапускать программу получается для сравнительно небольших файлов.
И если даже большой файл сожмется за более менее приемлемое время, то декомпрессия может затянуться очень сильно. Из-за того, что код Хаффмана неравномерный, 
невозможно проводить декомпрессию с использованием параллелизма, только последовательно.
- Если в исходном файле будут встречаться всевозможные байты, появляется вероятность того, что сжатие пройдет неудачно, поскольку в силу того, что код Хаффмана
префиксный, части байтов будут соответствовать кодовые слова, которые имеют длину более 8-ми бит. Если же помимо всего прочего, частоты встречаемости каждого
из байтов будут примерно равны, то применение алгоритма точно увеличит размер файла.

## Запуск алгоритма на файлах различного типа. Сравнение с ZIP, RAR, 7Z.

- Как показала практика, наиболее эффективно алгоритм сжимает осмысленные текстовые файлы. Причина лежит на поверхности: в большинстве языков можно выделить
наиболее часто встречающиеся буквы, причем частоты букв, встречающихся в текстах порой отличаются значительно. Здесь мы могли бы улучшить наш алгоритм, 
сделав в нем единицей гранулярности не байт, а UTF-8 символ. Возможно наши оппоненты как раз умеют смотреть шире, чем просто на один байт (напр. скользящее окно),
поэтому и сжимают файл лучше.

### shakespeare.txt
    | orig  | huff  | zip   | rar   | 7z    |
    |-------|-------|-------|-------|-------|
    | 99272 | 57067 | 40339 | 39116 | 36815 |

- Файл, заполненный (псевдо)случайными байтами из `/dev/urandom` любая из утилит сжать не смогла, а, наоборот, немного увеличила исходный файл в размерах, 
добавив туда кодовую таблицу, а также некоторые метаданные.

### random.bytes
    | orig    | huff    | zip     | rar     | 7z      |
    |---------|---------|---------|---------|---------|
    | 2605343 | 2606936 | 2605917 | 2605512 | 2605615 |

- Ради интереса решил провести эксперимент с пустым файлом. Ни одна из программ не "ругалась" и покорно оставила след в виде метаданных, и, возможно, 
вырожденной кодовой таблицы.

### empty.txt
    | orig | huff | zip | rar | 7z |
    |------|------|-----|-----|----|
    | 0    | 1    | 168 | 75  | 90 |

- Что касается изображений, с теоретической точки зрения могу сказать, что raw-изображение с весьма ограниченной палитрой цветов, сжалось бы с помощью моей 
программы хорошо. Но все изображения, которые мне удавалось найти в интернете, обычно уже сжаты (например, JPEG). Показываю результаты сжатия черно-белого 
JPEG-изображения. Видно, что ни одна из утилит не смогла значительно сжать изображение, несмотря на то, что оно черно-белое.

### bnw.jpeg

    | orig   | huff   | zip    | rar    | 7z     |
    |--------|--------|--------|--------|--------|
    | 135100 | 130150 | 128248 | 128106 | 127534 |

- Видео, как и изображения, находятся в сжатом виде очень много где, поскольку так просто выгоднее хранить (например, MP4). Здесь так же, как и с изображениями, 
не нашлось утилиты, которая бы продемонстрировала значительное сжатие. А моя программа даже увеличила размер файла. Дело в том, что в нем встречаются все
разновидности байтов, причем нет сильных выбросов по частотам. Длина некоторых кодовых слов достигает 10 бит.

### sample-5s.mp4
    | orig    | huff    | zip     | rar     | 7z      |
    |---------|---------|---------|---------|---------|
    | 2848208 | 2849127 | 2833087 | 2837091 | 2835415 |

- Интересный результат получился с WAV, который по умолчанию хранит внутри себя несжатые данные. 
Rar и 7Z справились значительно лучше своих коллег, более чем в два раза лучше, чем моя программа. 
В её защиту могу сказать, что в этом файле встречаются все виды байтов, а так же то, 
что WAV все-таки хранит внутри себя описание звуковых волн, поэтому хорошо было бы искать и сжимать повторяющиеся участки файла длиной более, чем байт.
В данном файле мелодия зациклена, что семантически говорит о возможности хорошо сжать этот файл.

### trap-drill-beat-boomy-drums-loop_120bpm.wav

    | orig    | huff    | zip     | rar     | 7z     |
    |---------|---------|---------|---------|--------|
    | 2986162 | 2916265 | 2031579 | 1158513 | 978776 |

